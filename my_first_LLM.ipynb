{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO6UZTR9M2nVXkaEIEXNR+r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danisoaresl/my_first_LLM/blob/main/my_first_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u52LGw6SS31t"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "# Import for retrieving secrets (optional)\n",
        "# from google.colab import userdata\n",
        "\n",
        "# Your API key (replace with your actual key)\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get ('SECRET_KEY')\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "generation_config = {\n",
        "  \"temperature\": 0.5,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 35,\n",
        "  \"max_output_tokens\": 1000,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"\",\n",
        "    \"threshold\": 0.0,\n",
        "  }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2F2UgOHdwN_"
      },
      "outputs": [],
      "source": [
        "import nump as np\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY='AIzaSyBq8AE_BFmQZ-5DjXiKYWEJuw_ox1coIiI'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "for m in genai.list_models():\n",
        "  if 'embedContent' in m.supported_generation_methods:\n",
        "    print(m.name)\n",
        "\n",
        "title = \"A próxima geração de IA\"\n",
        "sample_text = (\"Título: A próxima geração de IA\")\n",
        "\"\\n\"\n",
        "\"Artigo completo:\\n\"\n",
        "\"\\n\"\n",
        "\"Gemini API & Google AI Studio\"\n",
        "\n",
        "embeddings = genai.embed_content(model=\"models/embedding-001\",\n",
        "                                 content=sample_text,\n",
        "                                 title=tile,\n",
        "                                 task_type=\"RETRIEVAL_DOCUMENT\")\n",
        "print(embeddings)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Document1 = {\n",
        "\n",
        "}\n",
        "Document2 = {\n",
        "\n",
        "}\n",
        "Document3= {\n",
        "\n",
        "}\n",
        "documents = [Document1, Document2, Document3]\n",
        "\n"
      ],
      "metadata": {
        "id": "q5ghzF-eTZ1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "fYhgZDouokzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(documents)\n",
        "df.columns = [\"Título\", \"Conteudo\"]\n",
        "df"
      ],
      "metadata": {
        "id": "oIt_vdGNo1iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= \"models/embedding-001\"\n"
      ],
      "metadata": {
        "id": "U5nnhzMaqDTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MF8WmgWqKYG"
      },
      "outputs": [],
      "source": [
        "def emded_fn(title, text):\n",
        "  return genai.embed_content(model=model,\n",
        "                             content=text\n",
        "                             title=title,\n",
        "                             task_tiple=\"RETRIEVAL_DOCUMENT\")[\"embedding\"]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"embedding\"] = df.apply(lambda row: emdeb_fn(row[\"Título\"],row[\"Conteudo\"])axis=1)\n",
        "df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rPWWXtLqssLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_e_buscar_consulta(consulta, base, model):\n",
        "  embedding_da_consulta = genai.embed_content(model=model,\n",
        "                      content=consulta,\n",
        "                      task_type=\"RETRIEVAL_QUERY\")"
      ],
      "metadata": {
        "id": "qXqiGJThu7m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_e_buscar_consulta(consulta, base, model):\n",
        "  embedding_da_consulta = genai.embed_content(model=model,\n",
        "                                              content=consulta,\n",
        "                                              task_type=\"RETRIEVAL_QUERY\")\n",
        "\n",
        "  produtos_escolares = np.dot(np.stack(df[\"embeddings\"]), embedding_da_consulta[\"embeddings\"])\n",
        "\n",
        "  indice = np.argmax(produtos_escalares)\n",
        "  return df.iloc[indice][\"Conteudo\"]"
      ],
      "metadata": {
        "id": "USlBKhkRxFjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consulta = \"Como faço para trocar de marcha em um carro do Google?\"\n",
        "\n",
        "trecho = gerar_e_buscar_consulta(consulta, df, model)\n",
        "print(trecho)\n"
      ],
      "metadata": {
        "id": "KWhNhPvcXBH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"temperature\":0.5,\n",
        "    \"candidate_count\":1,\n",
        "}"
      ],
      "metadata": {
        "id": "z07x1tX6cGL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"Reescreva esse trecho de uma forma mais descontraída, sem adicionar informações que não façam parte do texto: {trecho}\"\n",
        "\n",
        "model_2 = genai.GenerativeModel(\"gemini-1.0-pro\",\n",
        "                                generation_config=generation_config)\n",
        "response = model_2.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "a0txpvd6dXri"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}